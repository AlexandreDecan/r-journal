<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE pdf2xml SYSTEM "pdf2xml.dtd">

<pdf2xml producer="poppler" version="0.30.0">
<page number="1" position="absolute" top="0" left="0" height="1262" width="892">
	<fontspec id="0" size="12" family="Times" color="#000000"/>
	<fontspec id="1" size="9" family="Times" color="#000000"/>
	<fontspec id="2" size="28" family="Times" color="#000000"/>
	<fontspec id="3" size="11" family="Times" color="#000000"/>
	<fontspec id="4" size="11" family="Times" color="#000000"/>
	<fontspec id="5" size="15" family="Times" color="#000000"/>
	<fontspec id="6" size="11" family="Times" color="#7282aa"/>
	<fontspec id="7" size="11" family="Times" color="#7282aa"/>
	<fontspec id="8" size="8" family="Times" color="#7282aa"/>
	<fontspec id="9" size="6" family="Times" color="#000000"/>
	<fontspec id="10" size="10" family="Times" color="#7282aa"/>
<text top="44" left="64" width="11" height="15" font="0">C</text>
<text top="47" left="75" width="86" height="12" font="1">ONTRIBUTED</text>
<text top="44" left="166" width="10" height="15" font="0">R</text>
<text top="47" left="177" width="61" height="12" font="1">ESEARCH</text>
<text top="44" left="242" width="12" height="15" font="0">A</text>
<text top="47" left="254" width="53" height="12" font="1">RTICLES</text>
<text top="44" left="822" width="7" height="15" font="0">6</text>
<text top="98" left="149" width="499" height="30" font="2"><b>RTextTools: A Supervised Learning</b></text>
<text top="137" left="149" width="430" height="30" font="2"><b>Package for Text Classification</b></text>
<text top="173" left="149" width="595" height="15" font="0">by Timothy P. Jurka, Loren Collingwood, Amber E. Boydstun, Emiliano Grossman, and Wouter van</text>
<text top="192" left="148" width="56" height="15" font="0">Atteveldt</text>
<text top="233" left="148" width="52" height="13" font="3"><b>Abstract</b></text>
<text top="233" left="207" width="538" height="13" font="4">Social scientists have long hand-labeled texts to create datasets useful for studying topics</text>
<text top="250" left="149" width="595" height="13" font="4">from congressional policymaking to media reporting. Many social scientists have begun to incorporate</text>
<text top="266" left="149" width="595" height="13" font="4">machine learning into their toolkits. <b>RTextTools </b>was designed to make machine learning accessible</text>
<text top="283" left="149" width="595" height="13" font="4">by providing a start-to-finish product in less than 10 steps. After installing <b>RTextTools</b>, the initial</text>
<text top="299" left="149" width="595" height="13" font="4">step is to generate a document term matrix. Second, a container object is created, which holds all</text>
<text top="315" left="149" width="598" height="13" font="4">the objects needed for further analysis. Third, users can use up to nine algorithms to train their data.</text>
<text top="332" left="149" width="596" height="13" font="4">Fourth, the data are classified. Fifth, the classification is summarized. Sixth, functions are available for</text>
<text top="348" left="148" width="596" height="13" font="4">performance evaluation. Seventh, ensemble agreement is conducted. Eighth, users can cross-validate</text>
<text top="365" left="149" width="595" height="13" font="4">their data. Finally, users write their data to a spreadsheet, allowing for further manual coding if</text>
<text top="381" left="149" width="54" height="13" font="4">required.</text>
<text top="426" left="149" width="104" height="17" font="5"><b>Introduction</b></text>
<text top="465" left="148" width="596" height="13" font="4">The process of hand-labeling texts according to topic, tone, and other quantifiable variables has yielded</text>
<text top="481" left="149" width="595" height="13" font="4">datasets offering insight into questions that span social science, such as the representation of citizen</text>
<text top="498" left="148" width="222" height="13" font="4">priorities in national policymaking <a href="2013-1-collingwood-jurka-boydstun-etal.html#6">(</a></text>
<text top="498" left="371" width="66" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">Jones et al.</a></text>
<text top="498" left="437" width="3" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">,</a></text>
<text top="498" left="445" width="27" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">2009</a></text>
<text top="498" left="472" width="272" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">) </a>and the effects of media framing on public</text>
<text top="514" left="149" width="56" height="13" font="4">opinion <a href="2013-1-collingwood-jurka-boydstun-etal.html#6">(</a></text>
<text top="514" left="205" width="114" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">Baumgartner et al.</a></text>
<text top="514" left="319" width="3" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">,</a></text>
<text top="514" left="326" width="27" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">2008</a></text>
<text top="514" left="354" width="391" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">). </a>This process of hand-labeling, known in the field as “manual</text>
<text top="531" left="149" width="595" height="13" font="4">coding”, is highly time consuming. To address this challenge, many social scientists have begun to</text>
<text top="547" left="149" width="595" height="13" font="4">incorporate machine learning into their toolkits. As computer scientists have long known, machine</text>
<text top="563" left="149" width="598" height="13" font="4">learning has the potential to vastly reduce the amount of time researchers spend manually coding data.</text>
<text top="580" left="148" width="596" height="13" font="4">Additionally, although machine learning cannot replicate the ability of a human coder to interpret the</text>
<text top="596" left="149" width="595" height="13" font="4">nuances of a text in context, it does allow researchers to examine systematically both texts and coding</text>
<text top="613" left="149" width="595" height="13" font="4">scheme performance in a way that humans cannot. Thus, the potential for heightened efficiency and</text>
<text top="629" left="148" width="596" height="13" font="4">perspective make machine learning an attractive approach for social scientists both with and without</text>
<text top="646" left="148" width="154" height="13" font="4">programming experience.</text>
<text top="667" left="171" width="573" height="13" font="4">Yet despite the rising interest in machine learning and the existence of several packages in R, no</text>
<text top="683" left="148" width="596" height="13" font="4">package incorporates a start-to-finish product that would be appealing to those social scientists and</text>
<text top="699" left="149" width="524" height="13" font="4">other researchers without technical expertise in this area. We offer to fill this gap through</text>
<text top="699" left="676" width="67" height="13" font="7"><a href="http://CRAN.R-project.org/package=RTextTools"><b>RTextTools</b></a></text>
<text top="699" left="743" width="3" height="13" font="4"><a href="http://CRAN.R-project.org/package=RTextTools">.</a></text>
<text top="716" left="149" width="595" height="13" font="4">Using a variety of existing R packages, <b>RTextTools </b>is designed as a one-stop-shop for conducting</text>
<text top="732" left="149" width="595" height="13" font="4">supervised learning with textual data. In this paper, we outline a nine-step process, discuss the core</text>
<text top="749" left="149" width="539" height="13" font="4">functions of the program, and demonstrate the use of <b>RTextTools </b>with a working example.</text>
<text top="770" left="171" width="573" height="13" font="4">The core philosophy driving <b>RTextTools</b>’ development is to create a package that is easy to use</text>
<text top="786" left="149" width="595" height="13" font="4">for individuals with no prior R experience, yet flexible enough for power users to utilize advanced</text>
<text top="803" left="149" width="595" height="13" font="4">techniques. Overall, <b>RTextTools </b>offers a comprehensive approach to text classification, by interfacing</text>
<text top="819" left="148" width="596" height="13" font="4">with existing text pre-processing routines and machine learning algorithms and by providing new</text>
<text top="835" left="149" width="595" height="13" font="4">analytics functions. While existing packages can be used to perform text preprocessing and machine</text>
<text top="852" left="149" width="595" height="13" font="4">learning, respectively, no package combines these processes with analytical functions for evaluating</text>
<text top="868" left="149" width="595" height="13" font="4">machine learning accuracy. In short, <b>RTextTools </b>expedites the text classification process: everything</text>
<text top="885" left="149" width="595" height="13" font="4">from the installation process to training and classifying has been streamlined to make machine learning</text>
<text top="901" left="148" width="181" height="13" font="4">with text data more accessible.</text>
<text top="946" left="149" width="149" height="17" font="5"><b>General workflow</b></text>
<text top="985" left="148" width="596" height="13" font="4">A user starts by loading his or her data from an Access, CSV, Excel file, or series of text files using</text>
<text top="1001" left="149" width="595" height="13" font="4">the read_data() function. We use a small and randomized subset of the congressional bills database</text>
<text top="1018" left="149" width="90" height="13" font="4">constructed by</text>
<text top="1018" left="242" width="128" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">Adler and Wilkerson</a></text>
<text top="1018" left="374" width="5" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">(</a></text>
<text top="1018" left="378" width="27" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">2004</a></text>
<text top="1018" left="406" width="237" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">) </a>for the running example offered her<a href="2013-1-collingwood-jurka-boydstun-etal.html#0">e.</a></text>
<text top="1015" left="643" width="5" height="10" font="8"><a href="2013-1-collingwood-jurka-boydstun-etal.html#0">1</a></text>
<text top="1018" left="654" width="90" height="13" font="4">We choose this</text>
<text top="1034" left="149" width="595" height="13" font="4">truncated dataset in order to minimize the amount of memory used, which can rapidly overwhelm a</text>
<text top="1051" left="149" width="598" height="13" font="4">computer when using large text corpora. Most users therefore should be able to reproduce the example.</text>
<text top="1067" left="149" width="597" height="13" font="4">However, the resulting predictions tend to improve (nonlinearly) with the size of the reference dataset,</text>
<text top="1083" left="149" width="595" height="13" font="4">meaning that our results here are not as good as they would be using the full congressional bills</text>
<text top="1100" left="149" width="595" height="13" font="4">dataset. Computers with at least 4GB of memory should be able to run <b>RTextTools </b>on medium to</text>
<text top="1116" left="149" width="595" height="13" font="4">large datasets (i.e., up to 30,000 texts) by using the three low-memory algorithms included: general</text>
<text top="1143" left="165" width="4" height="9" font="9"><a href="http://www.congressionalbills.org/research.html">1</a></text>
<text top="1146" left="170" width="287" height="10" font="10"><a href="http://www.congressionalbills.org/research.html">http://www.congressionalbills.org/research.html</a></text>
<text top="1210" left="148" width="186" height="15" font="0">The R Journal Vol. 5/1, June</text>
<text top="1210" left="642" width="102" height="15" font="0">ISSN 2073-4859</text>
</page>
<page number="2" position="absolute" top="0" left="0" height="1262" width="892">
	<fontspec id="11" size="10" family="Times" color="#000000"/>
<text top="44" left="64" width="11" height="15" font="0">C</text>
<text top="47" left="75" width="86" height="12" font="1">ONTRIBUTED</text>
<text top="44" left="166" width="10" height="15" font="0">R</text>
<text top="47" left="177" width="61" height="12" font="1">ESEARCH</text>
<text top="44" left="242" width="12" height="15" font="0">A</text>
<text top="47" left="254" width="53" height="12" font="1">RTICLES</text>
<text top="44" left="822" width="7" height="15" font="0">7</text>
<text top="103" left="149" width="115" height="13" font="4">linearized models <a href="2013-1-collingwood-jurka-boydstun-etal.html#6">(</a></text>
<text top="103" left="264" width="90" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">Friedman et al.</a></text>
<text top="103" left="355" width="3" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">,</a></text>
<text top="103" left="361" width="27" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">2010</a></text>
<text top="103" left="388" width="59" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">) </a>from the</text>
<text top="103" left="451" width="43" height="13" font="7"><a href="http://CRAN.R-project.org/package=glmnet"><b>glmnet</b></a></text>
<text top="103" left="498" width="177" height="13" font="4">package, maximum entropy <a href="2013-1-collingwood-jurka-boydstun-etal.html#6">(</a></text>
<text top="103" left="674" width="32" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">Jurka</a></text>
<text top="103" left="707" width="3" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">,</a></text>
<text top="103" left="714" width="27" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">2012</a></text>
<text top="103" left="741" width="5" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">)</a></text>
<text top="120" left="149" width="29" height="13" font="4">from</text>
<text top="120" left="182" width="45" height="13" font="7"><a href="http://CRAN.R-project.org/package=maxent"><b>maxent</b></a></text>
<text top="120" left="227" width="195" height="13" font="4"><a href="http://CRAN.R-project.org/package=maxent">, </a>and support vector machines <a href="2013-1-collingwood-jurka-boydstun-etal.html#6">(</a></text>
<text top="120" left="422" width="73" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">Meyer et al.</a></text>
<text top="120" left="495" width="3" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">,</a></text>
<text top="120" left="503" width="27" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">2012</a></text>
<text top="120" left="530" width="38" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">) </a>from</text>
<text top="120" left="572" width="34" height="13" font="7"><a href="http://CRAN.R-project.org/package=e1071"><b>e1071</b></a></text>
<text top="120" left="606" width="138" height="13" font="4"><a href="http://CRAN.R-project.org/package=e1071">. </a>For users with larger</text>
<text top="136" left="149" width="439" height="13" font="4">datasets, we recommend a cloud computing service such as Amazon EC2.</text>
<text top="181" left="149" width="160" height="17" font="5"><b>1. Creating a matrix</b></text>
<text top="220" left="149" width="348" height="13" font="4">First, we load our data with data(USCongress), and use the</text>
<text top="220" left="500" width="16" height="13" font="7"><a href="http://CRAN.R-project.org/package=tm"><b>tm</b></a></text>
<text top="220" left="520" width="56" height="13" font="4">package <a href="2013-1-collingwood-jurka-boydstun-etal.html#6">(</a></text>
<text top="220" left="576" width="79" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">Feinerer et al.</a></text>
<text top="220" left="654" width="3" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">,</a></text>
<text top="220" left="661" width="26" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">2008</a></text>
<text top="220" left="687" width="57" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">) </a>to create</text>
<text top="236" left="149" width="595" height="13" font="4">a document-term matrix. The USCongress dataset comes with <b>RTextTools </b>and hence the function data</text>
<text top="253" left="149" width="596" height="13" font="4">is relevant only to data emanating from R packages. Researchers with data in Access, CSV, Excel, or</text>
<text top="269" left="149" width="595" height="13" font="4">text files will want to load data via the read_data() function. Several pre-processing options from the</text>
<text top="286" left="149" width="16" height="13" font="3"><b>tm</b></text>
<text top="285" left="169" width="575" height="13" font="4">package are available at this stage, including stripping whitespace, removing sparse terms, word</text>
<text top="302" left="149" width="328" height="13" font="4">stemming, and stopword removal for several <a href="2013-1-collingwood-jurka-boydstun-etal.html#0">languages.</a></text>
<text top="299" left="477" width="5" height="10" font="8"><a href="2013-1-collingwood-jurka-boydstun-etal.html#0">2</a></text>
<text top="302" left="487" width="257" height="13" font="4">We want readers to be able to reproduce our</text>
<text top="318" left="149" width="595" height="13" font="4">example, so we set removeSparseTerms to .998, which vastly reduces the size of the document-term</text>
<text top="335" left="149" width="544" height="13" font="4">matrix, although it may also reduce accuracy in real-world applications. Users should consult</text>
<text top="335" left="696" width="48" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">Feinerer</a></text>
<text top="351" left="149" width="28" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">et al.</a></text>
<text top="351" left="180" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">(</a></text>
<text top="351" left="184" width="27" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">2008</a></text>
<text top="351" left="211" width="533" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">) </a>to take full advantage of preprocessing possibilities. Finally, note that the text column can</text>
<text top="368" left="149" width="595" height="13" font="4">be encapsulated in a cbind() data frame, which allows the user to perform supervised learning on</text>
<text top="384" left="149" width="179" height="13" font="4">multiple columns if necessary.</text>
<text top="414" left="149" width="110" height="11" font="4">data(USCongress)</text>
<text top="447" left="149" width="226" height="11" font="4"># CREATE THE DOCUMENT-TERM MATRIX</text>
<text top="464" left="149" width="576" height="11" font="4">doc_matrix &lt;- create_matrix(USCongress$text, language=&#34;english&#34;, removeNumbers=TRUE,</text>
<text top="480" left="341" width="268" height="11" font="4">stemWords=TRUE, removeSparseTerms=.998)</text>
<text top="525" left="149" width="184" height="17" font="5"><b>2. Creating a container</b></text>
<text top="563" left="148" width="596" height="13" font="4">The matrix is then partitioned into a container, which is essentially a list of objects that will be fed</text>
<text top="580" left="149" width="595" height="13" font="4">to the machine learning algorithms in the next step. The output is of class matrix_container and</text>
<text top="596" left="149" width="595" height="13" font="4">includes separate train and test sparse matrices, corresponding vectors of train and test codes, and a</text>
<text top="613" left="149" width="595" height="13" font="4">character vector of term label names. Looking at the example below, doc_matrix is the document term</text>
<text top="629" left="149" width="595" height="13" font="4">matrix created in the previous step, and USCongress$major is a vector of document labels taken from</text>
<text top="646" left="149" width="595" height="13" font="4">the USCongress dataset. trainSize and testSize indicate which documents to put into the training</text>
<text top="662" left="149" width="595" height="13" font="4">set and test set, respectively. The first 4,000 documents will be used to train the machine learning</text>
<text top="678" left="149" width="595" height="13" font="4">model, and the last 449 documents will be set aside to test the model. In principle, users do not have</text>
<text top="695" left="149" width="595" height="13" font="4">to store both documents and labels in a single dataset, although it greatly simplifies the process. So</text>
<text top="711" left="149" width="597" height="13" font="4">long as the documents correspond to the document labels via the trainSize and testSize parameters,</text>
<text top="728" left="149" width="123" height="11" font="4">create_container()</text>
<text top="728" left="276" width="468" height="13" font="4">will work properly. Finally, the virgin parameter is set to FALSE because we are</text>
<text top="744" left="149" width="442" height="13" font="4">still in the evaluation stage and not yet ready to classify virgin documents.</text>
<text top="775" left="149" width="528" height="11" font="4">container &lt;- create_container(doc_matrix, USCongress$major, trainSize=1:4000,</text>
<text top="791" left="355" width="226" height="11" font="4">testSize=4001:4449, virgin=FALSE)</text>
<text top="820" left="171" width="573" height="13" font="4">From this point, users pass the container into every subsequent function. An ensemble of up to</text>
<text top="837" left="149" width="269" height="13" font="4">nine algorithms can be trained and classified.</text>
<text top="882" left="149" width="153" height="17" font="5"><b>3. Training models</b></text>
<text top="920" left="148" width="596" height="13" font="4">The train_model() function takes each algorithm, one by one, to produce an object passable to</text>
<text top="937" left="149" width="110" height="11" font="4">classify_model()</text>
<text top="937" left="259" width="486" height="13" font="4">. A convenience train_models() function trains all models at once by passing in a</text>
<text top="953" left="148" width="148" height="13" font="4">vector of model requests<a href="2013-1-collingwood-jurka-boydstun-etal.html#0">.</a></text>
<text top="951" left="296" width="5" height="10" font="8"><a href="2013-1-collingwood-jurka-boydstun-etal.html#0">3</a></text>
<text top="953" left="306" width="438" height="13" font="4">The syntax below demonstrates model creation for all nine algorithms. For</text>
<text top="970" left="149" width="597" height="13" font="4">expediency, users replicating this analysis may want to use just the three low-memory algorithms:</text>
<text top="986" left="149" width="152" height="13" font="4">support vector machine <a href="2013-1-collingwood-jurka-boydstun-etal.html#6">(</a></text>
<text top="986" left="301" width="71" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">Meyer et al.</a></text>
<text top="986" left="372" width="3" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">,</a></text>
<text top="986" left="379" width="27" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">2012</a></text>
<text top="986" left="406" width="62" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">), </a>glmnet <a href="2013-1-collingwood-jurka-boydstun-etal.html#6">(</a></text>
<text top="986" left="468" width="91" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">Friedman et al.</a></text>
<text top="986" left="559" width="3" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">,</a></text>
<text top="986" left="566" width="27" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">2010</a></text>
<text top="986" left="593" width="151" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">), </a>and maximum entropy</text>
<text top="1003" left="148" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">(</a></text>
<text top="1003" left="153" width="31" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">Jurka</a></text>
<text top="1003" left="184" width="3" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">,</a></text>
<text top="1003" left="191" width="26" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">2012</a></text>
<text top="1003" left="217" width="8" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">).</a></text>
<text top="1000" left="225" width="5" height="10" font="8"><a href="2013-1-collingwood-jurka-boydstun-etal.html#0">4</a></text>
<text top="1003" left="235" width="509" height="13" font="4">The other six algorithms include: scaled linear discriminant analysis (slda) and bagging</text>
<text top="1019" left="148" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">(</a></text>
<text top="1019" left="153" width="116" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">Peters and Hothorn</a></text>
<text top="1019" left="269" width="3" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">,</a></text>
<text top="1019" left="275" width="27" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">2012</a></text>
<text top="1019" left="302" width="36" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">) </a>from</text>
<text top="1019" left="341" width="33" height="13" font="7"><a href="http://CRAN.R-project.org/package=ipred"><b>ipred</b></a></text>
<text top="1019" left="374" width="65" height="13" font="4"><a href="http://CRAN.R-project.org/package=ipred">; </a>boosting <a href="2013-1-collingwood-jurka-boydstun-etal.html#7">(</a></text>
<text top="1019" left="440" width="59" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#7">Tuszynski</a></text>
<text top="1019" left="499" width="3" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#7">,</a></text>
<text top="1019" left="506" width="27" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#7">2012</a></text>
<text top="1019" left="532" width="36" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#7">) </a>from</text>
<text top="1019" left="572" width="46" height="13" font="7"><a href="http://CRAN.R-project.org/package=caTools"><b>caTools</b></a></text>
<text top="1019" left="617" width="98" height="13" font="4"><a href="http://CRAN.R-project.org/package=caTools">; </a>random forest <a href="2013-1-collingwood-jurka-boydstun-etal.html#6">(</a></text>
<text top="1019" left="715" width="30" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">Liaw</a></text>
<text top="1035" left="149" width="69" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">and Wiener</a></text>
<text top="1035" left="218" width="3" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">,</a></text>
<text top="1035" left="225" width="27" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">2002</a></text>
<text top="1035" left="252" width="37" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">) </a>from</text>
<text top="1036" left="292" width="85" height="13" font="7"><a href="http://CRAN.R-project.org/package=randomForest"><b>randomForest</b></a></text>
<text top="1035" left="378" width="113" height="13" font="4"><a href="http://CRAN.R-project.org/package=randomForest">; </a>neural networks <a href="2013-1-collingwood-jurka-boydstun-etal.html#7">(</a></text>
<text top="1035" left="490" width="122" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#7">Venables and Ripley</a></text>
<text top="1035" left="613" width="3" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#7">,</a></text>
<text top="1035" left="619" width="27" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#7">2002</a></text>
<text top="1035" left="646" width="37" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#7">) </a>from</text>
<text top="1036" left="687" width="28" height="13" font="7"><a href="http://CRAN.R-project.org/package=nnet"><b>nnet</b></a></text>
<text top="1035" left="714" width="30" height="13" font="4"><a href="http://CRAN.R-project.org/package=nnet">; </a>and</text>
<text top="1052" left="149" width="191" height="13" font="4">classification or regression tree <a href="2013-1-collingwood-jurka-boydstun-etal.html#6">(</a></text>
<text top="1052" left="340" width="41" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">Ripley.</a></text>
<text top="1052" left="381" width="3" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">,</a></text>
<text top="1052" left="388" width="27" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">2012</a></text>
<text top="1052" left="415" width="37" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">) </a>from</text>
<text top="1052" left="455" width="23" height="13" font="7"><a href="http://CRAN.R-project.org/package=tree"><b>tree</b></a></text>
<text top="1052" left="478" width="266" height="13" font="4"><a href="http://CRAN.R-project.org/package=tree">. </a>Please see the aforementioned references to</text>
<text top="1079" left="165" width="4" height="9" font="9">2</text>
<text top="1081" left="170" width="575" height="12" font="1">Languages include Danish, Dutch, English, Finnish, French, German, Italian, Norwegian, Portuguese, Russian,</text>
<text top="1095" left="149" width="119" height="12" font="1">Spanish, and Swedish.</text>
<text top="1108" left="165" width="4" height="9" font="9">3</text>
<text top="1110" left="170" width="104" height="10" font="11">classify_models()</text>
<text top="1110" left="277" width="92" height="12" font="1">is the corollary to</text>
<text top="1110" left="372" width="85" height="10" font="11">train_models()</text>
<text top="1110" left="457" width="3" height="12" font="1">.</text>
<text top="1122" left="165" width="4" height="9" font="9">4</text>
<text top="1125" left="170" width="574" height="12" font="1">Training and classification time may take a few hours for all 9 algorithms, compared to a few minutes for the</text>
<text top="1139" left="149" width="131" height="12" font="1">low memory algorithms.</text>
<text top="1210" left="148" width="186" height="15" font="0">The R Journal Vol. 5/1, June</text>
<text top="1210" left="642" width="102" height="15" font="0">ISSN 2073-4859</text>
</page>
<page number="3" position="absolute" top="0" left="0" height="1262" width="892">
<text top="44" left="64" width="11" height="15" font="0">C</text>
<text top="47" left="75" width="86" height="12" font="1">ONTRIBUTED</text>
<text top="44" left="166" width="10" height="15" font="0">R</text>
<text top="47" left="177" width="61" height="12" font="1">ESEARCH</text>
<text top="44" left="242" width="12" height="15" font="0">A</text>
<text top="47" left="254" width="53" height="12" font="1">RTICLES</text>
<text top="44" left="822" width="7" height="15" font="0">8</text>
<text top="103" left="149" width="598" height="13" font="4">find out more about the specifics of these algorithms and the packages from which they originate.</text>
<text top="120" left="149" width="501" height="13" font="4">Finally, additional arguments can be passed to train_model() via the ... argument.</text>
<text top="150" left="149" width="240" height="11" font="4">SVM &lt;- train_model(container,&#34;SVM&#34;)</text>
<text top="166" left="149" width="281" height="11" font="4">GLMNET &lt;- train_model(container,&#34;GLMNET&#34;)</text>
<text top="183" left="149" width="281" height="11" font="4">MAXENT &lt;- train_model(container,&#34;MAXENT&#34;)</text>
<text top="199" left="149" width="254" height="11" font="4">SLDA &lt;- train_model(container,&#34;SLDA&#34;)</text>
<text top="216" left="149" width="309" height="11" font="4">BOOSTING &lt;- train_model(container,&#34;BOOSTING&#34;)</text>
<text top="232" left="149" width="295" height="11" font="4">BAGGING &lt;- train_model(container,&#34;BAGGING&#34;)</text>
<text top="249" left="149" width="226" height="11" font="4">RF &lt;- train_model(container,&#34;RF&#34;)</text>
<text top="265" left="149" width="254" height="11" font="4">NNET &lt;- train_model(container,&#34;NNET&#34;)</text>
<text top="282" left="149" width="254" height="11" font="4">TREE &lt;- train_model(container,&#34;TREE&#34;)</text>
<text top="326" left="149" width="330" height="17" font="5"><b>4. Classifying data using trained models</b></text>
<text top="365" left="148" width="596" height="13" font="4">The functions classify_model() and classify_models() use the same syntax as train_model(). Each</text>
<text top="381" left="149" width="595" height="13" font="4">model created in the previous step is passed on to classify_model(), which then returns the classified</text>
<text top="397" left="149" width="29" height="13" font="4">data.</text>
<text top="428" left="149" width="316" height="11" font="4">SVM_CLASSIFY &lt;- classify_model(container, SVM)</text>
<text top="444" left="149" width="357" height="11" font="4">GLMNET_CLASSIFY &lt;- classify_model(container, GLMNET)</text>
<text top="461" left="149" width="357" height="11" font="4">MAXENT_CLASSIFY &lt;- classify_model(container, MAXENT)</text>
<text top="477" left="149" width="329" height="11" font="4">SLDA_CLASSIFY &lt;- classify_model(container, SLDA)</text>
<text top="494" left="149" width="384" height="11" font="4">BOOSTING_CLASSIFY &lt;- classify_model(container, BOOSTING)</text>
<text top="510" left="149" width="370" height="11" font="4">BAGGING_CLASSIFY &lt;- classify_model(container, BAGGING)</text>
<text top="527" left="149" width="302" height="11" font="4">RF_CLASSIFY &lt;- classify_model(container, RF)</text>
<text top="543" left="149" width="329" height="11" font="4">NNET_CLASSIFY &lt;- classify_model(container, NNET)</text>
<text top="559" left="149" width="329" height="11" font="4">TREE_CLASSIFY &lt;- classify_model(container, TREE)</text>
<text top="604" left="149" width="97" height="17" font="5"><b>5. Analytics</b></text>
<text top="643" left="148" width="596" height="13" font="4">The most crucial step during the machine learning process is interpreting the results, and <b>RTextTools</b></text>
<text top="659" left="148" width="596" height="13" font="4">provides a function called create_analytics() to help users understand the classification of their</text>
<text top="675" left="149" width="596" height="13" font="4">test set data. The function returns a container with four different summaries: by label (e.g., topic), by</text>
<text top="692" left="149" width="313" height="13" font="4">algorithm, by document, and an ensemble summary.</text>
<text top="713" left="171" width="573" height="13" font="4">Each summary’s contents will differ depending on whether the virgin flag was set to TRUE or</text>
<text top="730" left="149" width="34" height="11" font="4">FALSE</text>
<text top="729" left="186" width="559" height="13" font="4">in the create_container() function in Step 3. For example, when the virgin flag is set to FALSE,</text>
<text top="746" left="149" width="597" height="13" font="4">indicating that all data in the training and testing sets have corresponding labels, create_analytics()</text>
<text top="762" left="148" width="596" height="13" font="4">will check the results of the learning algorithms against the true values to determine the accuracy of</text>
<text top="779" left="149" width="595" height="13" font="4">the process. However, if the virgin flag is set to TRUE, indicating that the testing set is unclassified data</text>
<text top="795" left="148" width="596" height="13" font="4">with no known true values, create_analytics() will return as much information as possible without</text>
<text top="811" left="149" width="286" height="13" font="4">comparing each predicted value to its true label.</text>
<text top="832" left="171" width="573" height="13" font="4">The label summary provides statistics for each unique label in the classified data (e.g., each topic</text>
<text top="849" left="149" width="598" height="13" font="4">category). This includes the number of documents that were manually coded with that unique la-</text>
<text top="865" left="149" width="595" height="13" font="4">bel (NUM_MANUALLY_CODED), the number of document sthat were coded using the ensemble method</text>
<text top="882" left="148" width="596" height="13" font="4">(NUM_CONSENSUS_CODED), the number of documents that were coded using the probability method</text>
<text top="898" left="148" width="596" height="13" font="4">(NUM_PROBABILITY_CODED), the rate of over- or under-coding with each method (PCT_CONSENSUS_CODED</text>
<text top="914" left="149" width="595" height="13" font="4">and PCT_PROBABILITY_CODED), and the percentage that were correctly coded using either the ensemble</text>
<text top="931" left="149" width="47" height="13" font="4">method</text>
<text top="931" left="227" width="13" height="13" font="4">or</text>
<text top="931" left="271" width="19" height="13" font="4">the</text>
<text top="931" left="321" width="67" height="13" font="4">probability</text>
<text top="931" left="419" width="47" height="13" font="4">method</text>
<text top="931" left="497" width="203" height="13" font="4">(PCT_CORRECTLY_CODED_CONSENSUS</text>
<text top="931" left="731" width="13" height="13" font="4">or</text>
<text top="948" left="149" width="213" height="11" font="4">PCT_CORRECTLY_CODED_PROBABILITY</text>
<text top="947" left="361" width="86" height="13" font="4">, respectively).</text>
<text top="968" left="171" width="573" height="13" font="4">The algorithm summary provides a breakdown of each algorithm’s performance for each unique</text>
<text top="985" left="149" width="595" height="13" font="4">label in the classified data. This includes metrics such as precision, recall, f-scores, and the accuracy of</text>
<text top="1001" left="149" width="318" height="13" font="4">each algorithm’s results as compared to the true <a href="2013-1-collingwood-jurka-boydstun-etal.html#0">data.</a></text>
<text top="998" left="466" width="5" height="10" font="8"><a href="2013-1-collingwood-jurka-boydstun-etal.html#0">5</a></text>
<text top="1022" left="171" width="575" height="13" font="4">The document summary provides all the raw data available for each document. By docu-</text>
<text top="1039" left="149" width="595" height="13" font="4">ment, it displays each algorithm’s prediction (ALGORITHM_LABEL), the algorithm’s probability score</text>
<text top="1055" left="148" width="596" height="13" font="4">(ALGORITHM_PROB), the number of algorithms that agreed on the same label (CONSENSUS_AGREE), which</text>
<text top="1071" left="149" width="595" height="13" font="4">algorithm had the highest probability score for its prediction (PROBABILITY_CODE), and the original</text>
<text top="1098" left="165" width="4" height="9" font="9">5</text>
<text top="1100" left="170" width="574" height="12" font="1">If a dataset is small (such as the present example), there is a chance that some f-score calculations will report</text>
<text top="1115" left="149" width="18" height="10" font="11">NaN</text>
<text top="1114" left="170" width="574" height="12" font="1">for some labels. This happens because not all labels were classified by a given algorithm (e.g., no cases were</text>
<text top="1129" left="149" width="318" height="12" font="1">given a 5). In most real-world datasets, this will not happen.</text>
<text top="1210" left="148" width="186" height="15" font="0">The R Journal Vol. 5/1, June</text>
<text top="1210" left="642" width="102" height="15" font="0">ISSN 2073-4859</text>
</page>
<page number="4" position="absolute" top="0" left="0" height="1262" width="892">
<text top="44" left="64" width="11" height="15" font="0">C</text>
<text top="47" left="75" width="86" height="12" font="1">ONTRIBUTED</text>
<text top="44" left="166" width="10" height="15" font="0">R</text>
<text top="47" left="177" width="61" height="12" font="1">ESEARCH</text>
<text top="44" left="242" width="12" height="15" font="0">A</text>
<text top="47" left="254" width="53" height="12" font="1">RTICLES</text>
<text top="44" left="822" width="7" height="15" font="0">9</text>
<text top="103" left="149" width="595" height="13" font="4">label of the document (MANUAL_CODE). Finally, the create_analytics() function outputs information</text>
<text top="120" left="148" width="416" height="13" font="4">pertaining to ensemble analysis, which is discussed in its own section.</text>
<text top="141" left="171" width="573" height="13" font="4">Summary and print methods are available for create_analytics(), but users can also store each</text>
<text top="157" left="149" width="595" height="13" font="4">summary in separate data frames for further analysis or writing to disk. Parameters include the</text>
<text top="173" left="149" width="397" height="13" font="4">container object and a matrix or cbind() object of classified r<a href="2013-1-collingwood-jurka-boydstun-etal.html#0">esults.</a></text>
<text top="171" left="546" width="5" height="10" font="8"><a href="2013-1-collingwood-jurka-boydstun-etal.html#0">6</a></text>
<text top="204" left="149" width="274" height="11" font="4">analytics &lt;- create_analytics(container,</text>
<text top="220" left="355" width="233" height="11" font="4">cbind(SVM_CLASSIFY, SLDA_CLASSIFY,</text>
<text top="237" left="396" width="247" height="11" font="4">BOOSTING_CLASSIFY, BAGGING_CLASSIFY,</text>
<text top="253" left="396" width="199" height="11" font="4">RF_CLASSIFY, GLMNET_CLASSIFY,</text>
<text top="270" left="396" width="199" height="11" font="4">NNET_CLASSIFY, TREE_CLASSIFY,</text>
<text top="286" left="396" width="117" height="11" font="4">MAXENT_CLASSIFY))</text>
<text top="302" left="149" width="123" height="11" font="4">summary(analytics)</text>
<text top="335" left="149" width="226" height="11" font="4"># CREATE THE data.frame SUMMARIES</text>
<text top="352" left="149" width="274" height="11" font="4">topic_summary &lt;- analytics@label_summary</text>
<text top="368" left="149" width="288" height="11" font="4">alg_summary &lt;- analytics@algorithm_summary</text>
<text top="385" left="149" width="274" height="11" font="4">ens_summary &lt;-analytics@ensemble_summary</text>
<text top="401" left="149" width="281" height="11" font="4">doc_summary &lt;- analytics@document_summary</text>
<text top="445" left="149" width="238" height="17" font="5"><b>6. Testing algorithm accuracy</b></text>
<text top="484" left="148" width="466" height="13" font="4">While there are many techniques used to evaluate algorithmic performance <a href="2013-1-collingwood-jurka-boydstun-etal.html#6">(</a></text>
<text top="484" left="614" width="132" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">McLaughlin and Her-</a></text>
<text top="501" left="149" width="37" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">locker</a></text>
<text top="501" left="186" width="3" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">,</a></text>
<text top="501" left="194" width="27" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">2004</a></text>
<text top="501" left="221" width="523" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">), </a>the summary call to create_analytics() produces precision, recall and f-scores for</text>
<text top="517" left="149" width="595" height="13" font="4">analyzing algorithmic performance at the aggregate level. Precision refers to how often a case the</text>
<text top="533" left="149" width="595" height="13" font="4">algorithm predicts as belonging to a class actually belongs to that class. For example, in the context</text>
<text top="550" left="149" width="595" height="13" font="4">of the USCongress data, precision tells us what proportion of bills an algorithm deems to be about</text>
<text top="566" left="149" width="597" height="13" font="4">defense are actually about defense (based on the gold standard of human-assigned labels). In contrast,</text>
<text top="583" left="149" width="596" height="13" font="4">recall refers to the proportion of bills in a class the algorithm correctly assigns to that class. In other</text>
<text top="599" left="148" width="596" height="13" font="4">words, what percentage of actual defense bills did the algorithm correctly classify? F-scores produce a</text>
<text top="616" left="148" width="597" height="13" font="4">weighted average of both precision and recall, where the highest level of performance is equal to 1</text>
<text top="632" left="149" width="105" height="13" font="4">and the lowest 0 <a href="2013-1-collingwood-jurka-boydstun-etal.html#6">(</a></text>
<text top="632" left="254" width="86" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">Sokolova et al.</a></text>
<text top="632" left="340" width="3" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">,</a></text>
<text top="632" left="347" width="27" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">2006</a></text>
<text top="632" left="374" width="8" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">).</a></text>
<text top="653" left="171" width="573" height="13" font="4">Users can quickly compare algorithm performance. For instance, our working example shows</text>
<text top="669" left="149" width="595" height="13" font="4">that the SVM, glmnet, maximum entropy, random forest, SLDA, and boosting vastly outperform the</text>
<text top="686" left="149" width="595" height="13" font="4">other algorithms in terms of f-scores, precision, and recall. For instance, SVM’s f-score is 0.65 whereas</text>
<text top="702" left="149" width="596" height="13" font="4">SLDA’s f-score is 0.63, essentially no difference. Thus, if analysts wish to only use one algorithm, any</text>
<text top="719" left="149" width="595" height="13" font="4">of these top algorithms will produce comparable results. Based on these results, Bagging, Tree, and</text>
<text top="735" left="149" width="197" height="13" font="4">NNET should not be used singly<a href="2013-1-collingwood-jurka-boydstun-etal.html#0">.</a></text>
<text top="732" left="346" width="5" height="10" font="8"><a href="2013-1-collingwood-jurka-boydstun-etal.html#0">7</a></text>
<text top="808" left="295" width="69" height="15" font="0">Algorithm</text>
<text top="808" left="414" width="60" height="15" font="0">Precision</text>
<text top="808" left="492" width="40" height="15" font="0">Recall</text>
<text top="808" left="550" width="47" height="15" font="0">F-score</text>
<text top="833" left="295" width="33" height="15" font="0">SVM</text>
<text top="833" left="448" width="26" height="15" font="0">0.67</text>
<text top="833" left="506" width="26" height="15" font="0">0.65</text>
<text top="833" left="571" width="26" height="15" font="0">0.65</text>
<text top="851" left="295" width="50" height="15" font="0">Glmnet</text>
<text top="851" left="448" width="26" height="15" font="0">0.68</text>
<text top="851" left="506" width="26" height="15" font="0">0.64</text>
<text top="851" left="571" width="26" height="15" font="0">0.64</text>
<text top="869" left="295" width="40" height="15" font="0">SLDA</text>
<text top="869" left="448" width="26" height="15" font="0">0.64</text>
<text top="869" left="506" width="26" height="15" font="0">0.63</text>
<text top="869" left="571" width="26" height="15" font="0">0.63</text>
<text top="887" left="295" width="101" height="15" font="0">Random Forest</text>
<text top="887" left="448" width="26" height="15" font="0">0.68</text>
<text top="887" left="506" width="26" height="15" font="0">0.62</text>
<text top="887" left="571" width="26" height="15" font="0">0.63</text>
<text top="905" left="295" width="50" height="15" font="0">Maxent</text>
<text top="905" left="448" width="26" height="15" font="0">0.60</text>
<text top="905" left="506" width="26" height="15" font="0">0.62</text>
<text top="905" left="571" width="26" height="15" font="0">0.60</text>
<text top="923" left="295" width="58" height="15" font="0">Boosting</text>
<text top="923" left="448" width="26" height="15" font="0">0.65</text>
<text top="923" left="506" width="26" height="15" font="0">0.59</text>
<text top="923" left="571" width="26" height="15" font="0">0.59</text>
<text top="941" left="295" width="55" height="15" font="0">Bagging</text>
<text top="941" left="448" width="26" height="15" font="0">0.52</text>
<text top="941" left="506" width="26" height="15" font="0">0.39</text>
<text top="941" left="571" width="26" height="15" font="0">0.39</text>
<text top="959" left="295" width="28" height="15" font="0">Tree</text>
<text top="959" left="448" width="26" height="15" font="0">0.20</text>
<text top="959" left="506" width="26" height="15" font="0">0.22</text>
<text top="959" left="571" width="26" height="15" font="0">0.18</text>
<text top="977" left="295" width="43" height="15" font="0">NNET</text>
<text top="977" left="448" width="26" height="15" font="0">0.07</text>
<text top="977" left="506" width="26" height="15" font="0">0.12</text>
<text top="977" left="571" width="26" height="15" font="0">0.08</text>
<text top="1013" left="278" width="47" height="13" font="3"><b>Table 1:</b></text>
<text top="1013" left="330" width="284" height="13" font="4">Overall algorithm precision, recall, and f-scores.</text>
<text top="1070" left="165" width="4" height="9" font="9">6</text>
<text top="1072" left="170" width="574" height="12" font="1">Users who conduct the analysis with the three low-memory algorithms will want to slightly modify the</text>
<text top="1086" left="149" width="82" height="12" font="1">following code.</text>
<text top="1099" left="165" width="4" height="9" font="9">7</text>
<text top="1101" left="170" width="574" height="12" font="1">Note that these results are specific to these data. The overall sample size is somewhat small. Bagging, Tree, and</text>
<text top="1115" left="149" width="193" height="12" font="1">NNET perform well with more data.</text>
<text top="1210" left="148" width="186" height="15" font="0">The R Journal Vol. 5/1, June</text>
<text top="1210" left="642" width="102" height="15" font="0">ISSN 2073-4859</text>
</page>
<page number="5" position="absolute" top="0" left="0" height="1262" width="892">
<text top="44" left="64" width="11" height="15" font="0">C</text>
<text top="47" left="75" width="86" height="12" font="1">ONTRIBUTED</text>
<text top="44" left="166" width="10" height="15" font="0">R</text>
<text top="47" left="177" width="61" height="12" font="1">ESEARCH</text>
<text top="44" left="242" width="12" height="15" font="0">A</text>
<text top="47" left="254" width="53" height="12" font="1">RTICLES</text>
<text top="44" left="814" width="15" height="15" font="0">10</text>
<text top="100" left="149" width="190" height="17" font="5"><b>7. Ensemble agreement</b></text>
<text top="139" left="148" width="596" height="13" font="4">We recommend ensemble (consensus) agreement to enhance labeling accuracy. Ensemble agreement</text>
<text top="155" left="149" width="595" height="13" font="4">simply refers to whether multiple algorithms make the same prediction concerning the class of an</text>
<text top="172" left="149" width="595" height="13" font="4">event (i.e., did SVM and maximum entropy assign the same label to the text?). Using a four-ensemble</text>
<text top="188" left="149" width="128" height="13" font="4">agreement approach,</text>
<text top="188" left="280" width="172" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">Collingwood and Wilkerson</a></text>
<text top="188" left="456" width="5" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">(</a></text>
<text top="188" left="460" width="27" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">2012</a></text>
<text top="188" left="488" width="256" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#6">) </a>found that when four of their algorithms</text>
<text top="205" left="149" width="595" height="13" font="4">agree on the label of a textual document, the machine label matches the human label over 90% of the</text>
<text top="221" left="149" width="446" height="13" font="4">time. The rate is just 45% when only two algorithms agree on the text label.</text>
<text top="242" left="171" width="67" height="13" font="3"><b>RTextTools</b></text>
<text top="242" left="242" width="504" height="13" font="4">includes create_ensembleSummary(), which calculates both recall accuracy and cover-</text>
<text top="258" left="149" width="595" height="13" font="4">age for <b>n </b>ensemble agreement. Coverage simply refers to the percentage of documents that meet the</text>
<text top="275" left="149" width="595" height="13" font="4">recall accuracy threshold. For instance, say we find that when seven algorithms agree on the label</text>
<text top="291" left="149" width="595" height="13" font="4">of a bill, our overall accuracy is 90% (when checked against our true values). Then, let’s say, we find</text>
<text top="308" left="149" width="595" height="13" font="4">that only 20% of our bills meet that criterion. If we have 10 bills and only two bills meet the seven</text>
<text top="324" left="149" width="595" height="13" font="4">ensemble agreement threshold, then our coverage is 20%. Mathematically, if k represents the percent</text>
<text top="341" left="149" width="595" height="13" font="4">of cases that meet the ensemble threshold, and n represents total cases, coverage is calculated in the</text>
<text top="357" left="149" width="90" height="13" font="4">following way:</text>
<text top="398" left="403" width="57" height="13" font="4">Coverage</text>
<text top="398" left="464" width="11" height="12" font="0">=</text>
<text top="389" left="481" width="6" height="13" font="4">k</text>
<text top="407" left="481" width="7" height="13" font="4">n</text>
<text top="398" left="728" width="16" height="13" font="4">(1)</text>
<text top="429" left="171" width="575" height="13" font="4">Users can test their accuracy using a variety of ensemble cut-points, which is demonstrated below.</text>
<text top="446" left="148" width="31" height="13" font="4">Table</text>
<text top="446" left="182" width="7" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#5">2</a></text>
<text top="446" left="192" width="552" height="13" font="4">reports the coverage and recall accuracy for different levels of ensemble agreement. The general</text>
<text top="462" left="149" width="595" height="13" font="4">trend is for coverage to decrease while recall increases. For example, just 11% of the congressional bills</text>
<text top="479" left="149" width="595" height="13" font="4">in our data have nine algorithms that agree. However, recall accuracy is 100% for those bills when the</text>
<text top="495" left="149" width="597" height="13" font="4">9 algorithms do agree. Considering that 90% is often social scientists’ inter-coder reliability standard,</text>
<text top="512" left="149" width="595" height="13" font="4">one may be comfortable using a 6 ensemble agreement with these data because we label 66% of the</text>
<text top="528" left="149" width="158" height="13" font="4">data with accuracy at <a href="2013-1-collingwood-jurka-boydstun-etal.html#0">90%.</a></text>
<text top="525" left="307" width="5" height="10" font="8"><a href="2013-1-collingwood-jurka-boydstun-etal.html#0">8</a></text>
<text top="575" left="149" width="343" height="11" font="4">create_ensembleSummary(analytics@document_summary)</text>
<text top="635" left="416" width="63" height="15" font="0">Coverage</text>
<text top="635" left="497" width="40" height="15" font="0">Recall</text>
<text top="660" left="356" width="42" height="15" font="0">n &gt;= 2</text>
<text top="660" left="453" width="26" height="15" font="0">1.00</text>
<text top="660" left="511" width="26" height="15" font="0">0.77</text>
<text top="678" left="356" width="42" height="15" font="0">n &gt;= 3</text>
<text top="678" left="453" width="26" height="15" font="0">0.98</text>
<text top="678" left="511" width="26" height="15" font="0">0.78</text>
<text top="696" left="356" width="42" height="15" font="0">n &gt;= 4</text>
<text top="696" left="453" width="26" height="15" font="0">0.90</text>
<text top="696" left="511" width="26" height="15" font="0">0.82</text>
<text top="714" left="356" width="42" height="15" font="0">n &gt;= 5</text>
<text top="714" left="453" width="26" height="15" font="0">0.78</text>
<text top="714" left="511" width="26" height="15" font="0">0.87</text>
<text top="732" left="356" width="42" height="15" font="0">n &gt;= 6</text>
<text top="732" left="453" width="26" height="15" font="0">0.66</text>
<text top="732" left="511" width="26" height="15" font="0">0.90</text>
<text top="750" left="356" width="42" height="15" font="0">n &gt;= 7</text>
<text top="750" left="453" width="26" height="15" font="0">0.45</text>
<text top="750" left="511" width="26" height="15" font="0">0.94</text>
<text top="768" left="356" width="42" height="15" font="0">n &gt;= 8</text>
<text top="768" left="453" width="26" height="15" font="0">0.29</text>
<text top="768" left="511" width="26" height="15" font="0">0.96</text>
<text top="786" left="356" width="42" height="15" font="0">n &gt;= 9</text>
<text top="786" left="453" width="26" height="15" font="0">0.11</text>
<text top="786" left="511" width="26" height="15" font="0">1.00</text>
<text top="822" left="298" width="47" height="13" font="3"><b>Table 2:</b></text>
<text top="822" left="349" width="245" height="13" font="4">Ensemble agreement coverage and recall.</text>
<text top="900" left="149" width="153" height="17" font="5"><b>8. Cross validation</b></text>
<text top="939" left="149" width="595" height="13" font="4">Users may use n-fold cross validation to calculate the accuracy of each algorithm on their dataset and</text>
<text top="956" left="149" width="357" height="13" font="4">determine which algorithms to use in their ensemble.</text>
<text top="956" left="525" width="67" height="13" font="3"><b>RTextTools</b></text>
<text top="956" left="600" width="144" height="13" font="4">provides a convenient</text>
<text top="973" left="149" width="110" height="11" font="4">cross_validate()</text>
<text top="972" left="263" width="483" height="13" font="4">function to perform n-fold cross validation. Note that when deciding the ap-</text>
<text top="988" left="148" width="596" height="13" font="4">propriate n-fold it is important to consider the total sample size so that enough data are in both the</text>
<text top="1005" left="149" width="258" height="13" font="4">train and test sets to produce useful results.</text>
<text top="1035" left="149" width="288" height="11" font="4">SVM &lt;- cross_validate(container, 4, &#34;SVM&#34;)</text>
<text top="1052" left="149" width="329" height="11" font="4">GLMNET &lt;- cross_validate(container, 4, &#34;GLMNET&#34;)</text>
<text top="1068" left="149" width="329" height="11" font="4">MAXENT &lt;- cross_validate(container, 4, &#34;MAXENT&#34;)</text>
<text top="1085" left="149" width="302" height="11" font="4">SLDA &lt;- cross_validate(container, 4, &#34;SLDA&#34;)</text>
<text top="1101" left="149" width="343" height="11" font="4">BAGGING &lt;- cross_validate(container, 4, &#34;BAGGING&#34;)</text>
<text top="1118" left="149" width="357" height="11" font="4">BOOSTING &lt;- cross_validate(container, 4, &#34;BOOSTING&#34;)</text>
<text top="1142" left="165" width="4" height="9" font="9">8</text>
<text top="1144" left="170" width="499" height="12" font="1">This result is excellent, given that the training data consist of just a few thousand observations.</text>
<text top="1210" left="148" width="186" height="15" font="0">The R Journal Vol. 5/1, June</text>
<text top="1210" left="642" width="102" height="15" font="0">ISSN 2073-4859</text>
</page>
<page number="6" position="absolute" top="0" left="0" height="1262" width="892">
<text top="44" left="64" width="11" height="15" font="0">C</text>
<text top="47" left="75" width="86" height="12" font="1">ONTRIBUTED</text>
<text top="44" left="166" width="10" height="15" font="0">R</text>
<text top="47" left="177" width="61" height="12" font="1">ESEARCH</text>
<text top="44" left="242" width="12" height="15" font="0">A</text>
<text top="47" left="254" width="53" height="12" font="1">RTICLES</text>
<text top="44" left="814" width="15" height="15" font="0">11</text>
<text top="104" left="149" width="274" height="11" font="4">RF &lt;- cross_validate(container, 4, &#34;RF&#34;)</text>
<text top="120" left="149" width="302" height="11" font="4">NNET &lt;- cross_validate(container, 4, &#34;NNET&#34;)</text>
<text top="137" left="149" width="302" height="11" font="4">TREE &lt;- cross_validate(container, 4, &#34;TREE&#34;)</text>
<text top="181" left="149" width="139" height="17" font="5"><b>9. Exporting data</b></text>
<text top="220" left="149" width="595" height="13" font="4">Finally, some users may want to write out the newly labeled data for continued manual labeling on</text>
<text top="236" left="149" width="595" height="13" font="4">texts that do not achieve high enough accuracy requirements during ensemble agreement. Researchers</text>
<text top="253" left="149" width="595" height="13" font="4">can then have human coders verify and label these data to improve accuracy. In this case, the document</text>
<text top="269" left="149" width="518" height="13" font="4">summary object generated from create_analytics can be easily exported to a CSV file.</text>
<text top="299" left="149" width="412" height="11" font="4">write.csv(analytics@document_summary, &#34;DocumentSummary.csv&#34;)</text>
<text top="344" left="149" width="94" height="17" font="5"><b>Conclusion</b></text>
<text top="382" left="148" width="596" height="13" font="4">Although a user can get started with <b>RTextTools </b>in less than ten steps, many more options are available</text>
<text top="399" left="149" width="595" height="13" font="4">that help to remove noise, refine trained models, and ultimately improve accuracy. If you want more</text>
<text top="415" left="149" width="595" height="13" font="4">control over your data, please refer to the documentation bundled with the package. Moreover, we</text>
<text top="432" left="149" width="596" height="13" font="4">hope that the package will become increasingly useful and flexible over time as advanced users develop</text>
<text top="448" left="149" width="595" height="13" font="4">add-on functions. <b>RTextTools </b>is completely open-source, and a link to the source code repository as</text>
<text top="465" left="148" width="420" height="13" font="4">well as a host of other information can be found at the project’s website –</text>
<text top="465" left="572" width="171" height="11" font="6"><a href="http://www.rtexttools.com">http://www.rtexttools.com</a></text>
<text top="465" left="743" width="3" height="13" font="4"><a href="http://www.rtexttools.com">.</a></text>
<text top="510" left="149" width="109" height="17" font="5"><b>Bibliography</b></text>
<text top="548" left="149" width="352" height="13" font="4">E. S. Adler and J. Wilkerson. Congressional Bills Project. URL</text>
<text top="549" left="504" width="206" height="11" font="6"><a href="http://congressionalbills.org/">http://congressionalbills.org/</a></text>
<text top="548" left="710" width="37" height="13" font="4"><a href="http://congressionalbills.org/">, </a>2004.</text>
<text top="565" left="164" width="13" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#1">[p</a></text>
<text top="565" left="176" width="7" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#1">6</a></text>
<text top="565" left="183" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#1">]</a></text>
<text top="593" left="149" width="595" height="13" font="4">F. Baumgartner, S. De Boef, and A. Boydstun. The Decline of the Death Penalty and the Discovery of</text>
<text top="609" left="164" width="285" height="14" font="4">Innocence. Cambridge University Press, 2008. <a href="2013-1-collingwood-jurka-boydstun-etal.html#1">[p</a></text>
<text top="610" left="448" width="7" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#1">6</a></text>
<text top="610" left="455" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#1">]</a></text>
<text top="638" left="149" width="598" height="13" font="4">L. Collingwood and J. Wilkerson. Tradeoffs in accuracy and efficiency in supervised learning methods.</text>
<text top="654" left="164" width="378" height="14" font="4">Journal of Information Technology &amp; Politics, 9(3):298–318, 2012. <a href="2013-1-collingwood-jurka-boydstun-etal.html#5">[p</a></text>
<text top="654" left="541" width="13" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#5">10</a></text>
<text top="654" left="555" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#5">]</a></text>
<text top="683" left="149" width="595" height="13" font="4">I. Feinerer, K. Hornik, and D. Meyer. Text mining infrastructure in R. Journal of Statistical Software, 25</text>
<text top="699" left="163" width="100" height="13" font="4">(5):1–54, 2008. <a href="2013-1-collingwood-jurka-boydstun-etal.html#2">[p</a></text>
<text top="699" left="264" width="7" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">7</a></text>
<text top="699" left="270" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">]</a></text>
<text top="728" left="149" width="595" height="13" font="4">J. Friedman, T. Hastie, and R. Tibshirani. Regularization paths for generalized linear models via</text>
<text top="744" left="164" width="383" height="13" font="4">coordinate descent. Journal of Statistical Software, 33(1):1, 2010. <a href="2013-1-collingwood-jurka-boydstun-etal.html#2">[p</a></text>
<text top="744" left="546" width="7" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">7</a></text>
<text top="744" left="553" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">]</a></text>
<text top="772" left="149" width="595" height="13" font="4">B. Jones, H. Larsen-Price, and J. Wilkerson. Representation and American governing institutions. The</text>
<text top="789" left="164" width="245" height="14" font="4">Journal of Politics, 71(01):277–290, 2009. <a href="2013-1-collingwood-jurka-boydstun-etal.html#1">[p</a></text>
<text top="789" left="409" width="7" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#1">6</a></text>
<text top="789" left="415" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#1">]</a></text>
<text top="817" left="149" width="596" height="13" font="4">T. P. Jurka. maxent: An R package for low-memory multinomial logistic regression with support for</text>
<text top="834" left="164" width="437" height="13" font="4">semi-automated text classification. The R Journal, 4(1):56–59, June 2012. <a href="2013-1-collingwood-jurka-boydstun-etal.html#2">[p</a></text>
<text top="834" left="601" width="7" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">7</a></text>
<text top="834" left="607" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">]</a></text>
<text top="862" left="149" width="584" height="13" font="4">A. Liaw and M. Wiener. Classification and regression by randomForest. R News, 2(3):18–22, 2002. <a href="2013-1-collingwood-jurka-boydstun-etal.html#2">[p</a></text>
<text top="862" left="733" width="7" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">7</a></text>
<text top="862" left="740" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">]</a></text>
<text top="891" left="149" width="595" height="13" font="4">M. McLaughlin and J. Herlocker. A collaborative filtering algorithm and evaluation metric that</text>
<text top="907" left="164" width="580" height="13" font="4">accurately model the user experience. In Proceedings of the 27th Annual International ACM SIGIR</text>
<text top="923" left="163" width="547" height="14" font="4">Conference on Research and Development in Information Retrieval, pages 329–336. ACM, 2004. <a href="2013-1-collingwood-jurka-boydstun-etal.html#4">[p</a></text>
<text top="923" left="711" width="7" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#4">9</a></text>
<text top="923" left="718" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#4">]</a></text>
<text top="952" left="149" width="595" height="13" font="4">D. Meyer, E. Dimitriadou, K. Hornik, A. Weingessel, and F. Leisch. e1071: Misc Functions of the</text>
<text top="968" left="163" width="308" height="14" font="4">Department of Statistics (e1071), TU Wien, 2012. URL</text>
<text top="969" left="475" width="268" height="11" font="6"><a href="http://CRAN.R-project.org/package=e1071">http://CRAN.R-project.org/package=e1071</a></text>
<text top="968" left="743" width="3" height="13" font="4"><a href="http://CRAN.R-project.org/package=e1071">.</a></text>
<text top="985" left="164" width="161" height="13" font="4">R package version 1.6-1. <a href="2013-1-collingwood-jurka-boydstun-etal.html#2">[p</a></text>
<text top="985" left="325" width="7" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">7</a></text>
<text top="985" left="331" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">]</a></text>
<text top="1013" left="149" width="358" height="13" font="4">A. Peters and T. Hothorn. ipred: Improved Predictors, 2012. URL</text>
<text top="1014" left="510" width="234" height="11" font="6"><a href="http://CRAN.R-project.org/package=ipred">http://CRAN.R-project.org/package=</a></text>
<text top="1030" left="164" width="34" height="11" font="6"><a href="http://CRAN.R-project.org/package=ipred">ipred</a></text>
<text top="1030" left="198" width="176" height="13" font="4"><a href="http://CRAN.R-project.org/package=ipred">. </a>R package version 0.8-13. <a href="2013-1-collingwood-jurka-boydstun-etal.html#2">[p</a></text>
<text top="1030" left="374" width="7" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">7</a></text>
<text top="1030" left="381" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">]</a></text>
<text top="1058" left="149" width="358" height="13" font="4">B. Ripley. tree: Classification and Regression Trees, 2012. URL</text>
<text top="1058" left="510" width="234" height="11" font="6"><a href="http://CRAN.R-project.org/package=tree">http://CRAN.R-project.org/package=</a></text>
<text top="1075" left="164" width="27" height="11" font="6"><a href="http://CRAN.R-project.org/package=tree">tree</a></text>
<text top="1074" left="191" width="176" height="13" font="4"><a href="http://CRAN.R-project.org/package=tree">. </a>R package version 1.0-31. <a href="2013-1-collingwood-jurka-boydstun-etal.html#2">[p</a></text>
<text top="1074" left="367" width="7" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">7</a></text>
<text top="1074" left="374" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">]</a></text>
<text top="1103" left="149" width="595" height="13" font="4">M. Sokolova, N. Japkowicz, and S. Szpakowicz. Beyond accuracy, F-score and ROC: a family of</text>
<text top="1119" left="164" width="582" height="13" font="4">discriminant measures for performance evaluation. In AI 2006: Advances in Artificial Intelligence,</text>
<text top="1136" left="163" width="210" height="13" font="4">pages 1015–1021, Springer, 2006. <a href="2013-1-collingwood-jurka-boydstun-etal.html#4">[p</a></text>
<text top="1136" left="373" width="7" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#4">9</a></text>
<text top="1136" left="380" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#4">]</a></text>
<text top="1210" left="148" width="186" height="15" font="0">The R Journal Vol. 5/1, June</text>
<text top="1210" left="642" width="102" height="15" font="0">ISSN 2073-4859</text>
</page>
<page number="7" position="absolute" top="0" left="0" height="1262" width="892">
<text top="44" left="64" width="11" height="15" font="0">C</text>
<text top="47" left="75" width="86" height="12" font="1">ONTRIBUTED</text>
<text top="44" left="166" width="10" height="15" font="0">R</text>
<text top="47" left="177" width="61" height="12" font="1">ESEARCH</text>
<text top="44" left="242" width="12" height="15" font="0">A</text>
<text top="47" left="254" width="53" height="12" font="1">RTICLES</text>
<text top="44" left="814" width="15" height="15" font="0">12</text>
<text top="103" left="149" width="561" height="13" font="4">J. Tuszynski. caTools: Tools: Moving Window Statistics, GIF, Base64, ROC AUC, etc., 2012. URL</text>
<text top="104" left="713" width="34" height="11" font="6"><a href="http://CRAN.R-project.org/package=caTools">http:</a></text>
<text top="120" left="163" width="248" height="11" font="6"><a href="http://CRAN.R-project.org/package=caTools">//CRAN.R-project.org/package=caTools</a></text>
<text top="120" left="411" width="165" height="13" font="4"><a href="http://CRAN.R-project.org/package=caTools">. </a>R package version 1.13. <a href="2013-1-collingwood-jurka-boydstun-etal.html#2">[p</a></text>
<text top="120" left="575" width="7" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">7</a></text>
<text top="120" left="582" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">]</a></text>
<text top="148" left="149" width="598" height="13" font="4">W. Venables and B. Ripley. Modern Applied Statistics with S. Springer, New York, fourth edition, 2002.</text>
<text top="164" left="164" width="13" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">[p</a></text>
<text top="164" left="176" width="7" height="13" font="6"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">7</a></text>
<text top="164" left="183" width="4" height="13" font="4"><a href="2013-1-collingwood-jurka-boydstun-etal.html#2">]</a></text>
<text top="208" left="148" width="91" height="13" font="4">Timothy P. Jurka</text>
<text top="224" left="148" width="171" height="13" font="4">Department of Political Science</text>
<text top="241" left="148" width="169" height="13" font="4">University of California, Davis</text>
<text top="257" left="148" width="110" height="13" font="4">One Shields Avenue</text>
<text top="273" left="148" width="95" height="13" font="4">Davis, CA 95616</text>
<text top="290" left="148" width="28" height="13" font="4">USA</text>
<text top="307" left="149" width="130" height="11" font="6"><a href="mailto:tpjurka@ucdavis.edu">tpjurka@ucdavis.edu</a></text>
<text top="344" left="148" width="103" height="13" font="4">Loren Collingwood</text>
<text top="360" left="148" width="171" height="13" font="4">Department of Political Science</text>
<text top="377" left="148" width="188" height="13" font="4">University of California, Riverside</text>
<text top="393" left="149" width="127" height="13" font="4">900 University Avenue</text>
<text top="409" left="148" width="113" height="13" font="4">Riverside, CA 92521</text>
<text top="426" left="148" width="28" height="13" font="4">USA</text>
<text top="443" left="149" width="171" height="11" font="6"><a href="mailto:loren.collingwood@ucr.edu">loren.collingwood@ucr.edu</a></text>
<text top="480" left="148" width="107" height="13" font="4">Amber E. Boydstun</text>
<text top="496" left="148" width="171" height="13" font="4">Department of Political Science</text>
<text top="513" left="148" width="169" height="13" font="4">University of California, Davis</text>
<text top="529" left="148" width="110" height="13" font="4">One Shields Avenue</text>
<text top="545" left="148" width="95" height="13" font="4">Davis, CA 95616</text>
<text top="562" left="148" width="28" height="13" font="4">USA</text>
<text top="579" left="149" width="144" height="11" font="6"><a href="mailto:aboydstun@ucdavis.edu">aboydstun@ucdavis.edu</a></text>
<text top="208" left="454" width="108" height="13" font="4">Emiliano Grossman</text>
<text top="224" left="454" width="96" height="13" font="4">Sciences Po /CEE</text>
<text top="241" left="454" width="130" height="13" font="4">28, rue des Saints-Pères</text>
<text top="257" left="454" width="65" height="13" font="4">75007 Paris</text>
<text top="273" left="454" width="37" height="13" font="4">France</text>
<text top="291" left="454" width="219" height="11" font="6"><a href="mailto:emiliano.grossman@sciences-po.fr">emiliano.grossman@sciences-po.fr</a></text>
<text top="327" left="453" width="119" height="13" font="4">Wouter van Atteveldt</text>
<text top="344" left="453" width="200" height="13" font="4">Communication Science Department</text>
<text top="360" left="453" width="96" height="13" font="4">Vrije Universiteit</text>
<text top="377" left="454" width="103" height="13" font="4">de Boelelaan 1081a</text>
<text top="393" left="453" width="117" height="13" font="4">1081 HV Amsterdam</text>
<text top="409" left="453" width="90" height="13" font="4">The Netherlands</text>
<text top="427" left="454" width="158" height="11" font="6"><a href="mailto:wouter@vanatteveldt.com">wouter@vanatteveldt.com</a></text>
<text top="1210" left="148" width="186" height="15" font="0">The R Journal Vol. 5/1, June</text>
<text top="1210" left="642" width="102" height="15" font="0">ISSN 2073-4859</text>
</page>
</pdf2xml>
